{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile applications: Users segmentation based on behavior.\n",
    "\n",
    "1. **Introduction**\n",
    "\n",
    "* Overview of the Project: Explain the purpose and importance of the project.\n",
    "* Goals and Objectives: Define what you aim to achieve with the user segmentation analysis.\n",
    "* Data Description: Describe the datasets used in the analysis.\n",
    "\n",
    "2.  **Data Loading and Preparation**\n",
    "\n",
    "* Load Datasets: Load mobile_dataset_us.csv and mobile_sources_us.csv.\n",
    "* Inspect and Clean the Data:\n",
    "* Handle missing values and incorrect data types.\n",
    "* Convert event.time to datetime format.\n",
    "* Check for and handle duplicates.\n",
    "* Merge Datasets: Merge the datasets for comprehensive analysis.\n",
    "* Rename Columns: Standardize column names (e.g., replace periods with underscores).\n",
    "* Event Name Cleanup:\n",
    "    * Rename contact_show to show_contacts.\n",
    "    * Consolidate search events (search_1, search_2, search_3, etc.) into a single search category.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "* Summary Statistics: Generate descriptive statistics for the dataset.\n",
    "* Data Visualization:\n",
    "    * Distribution of Events Over Time: Visualize how events are distributed over time.\n",
    "    * User Activity Distribution: Plot the number of events per user.\n",
    "    * Source Distribution: Analyze the distribution of user sources.\n",
    "Day of the Week Analysis: Visualize event distribution across different days of the week.\n",
    "* Insights and Initial Observations: Highlight critical findings from the EDA.\n",
    "\n",
    "4. ** User Segmentation** \n",
    "\n",
    "* Define Segmentation Criteria: Based on user events and behavior, define the criteria for segmenting users.\n",
    "* Segment Users: Apply k-means clustering to segment users into four distinct clusters..\n",
    "\n",
    "5. **Hypothesis Testing**\n",
    "\n",
    "* Formulate and Test Hypotheses:\n",
    "\n",
    "    * Conversion Difference: Test the hypothesis about the difference in conversion rates for contact information views between users from Bing and Google.\n",
    "    * Additional Hypotheses: Formulate and test additional hypotheses based on EDA findings.\n",
    "\n",
    "* Statistical Tests: Conduct statistical tests (e.g., t-tests, chi-square tests) to validate the hypotheses.\n",
    "* Interpretation of Results: Interpret the test results and derive conclusions.\n",
    "\n",
    "6. **Conclusions abd Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project, with the potential to significantly impact our user experience and engagement, aims to analyze users' actions in the application to define groups that differ in product metrics (retention rate, time spent in the application, frequency of event occurrence, conversion on the target event, contacts_show `).\n",
    "\n",
    "Throughout the project, we will:\n",
    "\n",
    "- Carry out exploratory data analysis\n",
    "- Segments users based on the events they complete\n",
    "- Test statistical hypotheses\n",
    "    - Formulate and test a hypothesis about the difference in conversion in contact information views between those who downloaded the app from `bing` and those who downloaded it from `google`.\n",
    "    - Formulate a statistical hypothesis about the dataset data and test it.\n",
    "\n",
    "**Data Description**\n",
    "\n",
    "The datasets contain data about events in the Trash to Treasure mobile app, where users post ads to sell things they no longer need.\n",
    "\n",
    "The data corresponds to those who took their first actions in the application after October 7, 2019.\n",
    "\n",
    "`mobile_dataset_us.csv` contains the following columns:\n",
    "\n",
    "- `event.time`: when the event took place\n",
    "- `event.name`\n",
    "- `user.id`\n",
    "\n",
    "`mobile_sources_us.csv` contains the following columns:\n",
    "\n",
    "- `userId`: user ID\n",
    "- `source`: the source from which the user downloaded the application\n",
    "\n",
    "Event details:\n",
    "\n",
    "- `advert_open`: open an advertising post\n",
    "- `photos_show`: see photos in the ad\n",
    "- `tips_show`:  the user was shown recommended ads\n",
    "- `tips_click`: the user clicked on a recommended ad\n",
    "- `contacts_show` and `show_contacts`: the user clicked the \"show phone number\" button in the ad\n",
    "- `contacts_call`: the user dialed the announcement number\n",
    "- `map`: the user opened the map of the published ads\n",
    "- `search_1` - `search_7`: various events related to website search\n",
    "- `favorites_add`: the user added the ad to favorites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_1samp, chi2_contingency\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load datasets\n",
    "mobile_dataset = pd.read_csv('mobile_dataset_us.csv')\n",
    "mobile_sources = pd.read_csv('mobile_sources_us.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows of the each data set\n",
    "mobile_dataset.head()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_sources.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display basic information about data sets\n",
    "mobile_dataset.info(), mobile_sources.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and inspecting the datasets, we'll handle missing values and ensure data types are appropriate.\n",
    "\n",
    "Next, let's merge the datasets for comprehensive analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on user ID\n",
    "merged_data = pd.merge(mobile_dataset, mobile_sources, left_on='user.id', right_on='userId')\n",
    "\n",
    "# Drop the redundant userId column\n",
    "merged_data.drop(columns=['userId'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "merged_data.head()\n",
    "merged_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Overview:\n",
    "\n",
    "mobile_dataset_us.csv\n",
    "- Columns: event.time, event.name, user.id\n",
    "- Entries: 74,197\n",
    "- Data Types: All columns are of type object\n",
    "\n",
    "mobile_sources_us.csv\n",
    "Columns: userId, source\n",
    "Entries: 4,293\n",
    "Data Types: Both columns are of type object\n",
    "\n",
    "Merged Dataset\n",
    "Columns: event.time, event.name, user.id, source\n",
    "Entries: 74,197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to replace periods with underscores\n",
    "merged_data.rename(columns={'event.time': 'event_time', 'event.name': 'event_name', 'user.id': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "merged_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "merged_data.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'event_time' to datetime\n",
    "merged_data['event_time'] = pd.to_datetime(merged_data['event_time'])\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename contact_show to show_contacts and combine all search events into a single 'search' category\n",
    "merged_data['event_name'] = merged_data['event_name'].replace({\n",
    "    'search_1': 'search',\n",
    "    'search_2': 'search',\n",
    "    'search_3': 'search',\n",
    "    'search_4': 'search',\n",
    "    'search_5': 'search',\n",
    "    'search_6': 'search',\n",
    "    'search_7': 'search',\n",
    "    'contact_show': 'show_contacts'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a summary of statistics to get an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event Distribution:\n",
    "\n",
    "The dataset contains a total of 74,197 events.\n",
    "There are 16 unique event types, with tips_show being the most frequent event, occurring 40,055 times.\n",
    "This suggests that viewing tips or recommendations is a common user action in the app.\n",
    "User Activity:\n",
    "\n",
    "The dataset includes 4,293 unique users.\n",
    "The most active user (user_id cb36854f-570a-41f4-baa8-36680b396370) performed 478 events.\n",
    "This indicates a significant disparity in user activity, with some users being much more active than others.\n",
    "\n",
    "Source Distribution:\n",
    "\n",
    "There are 3 unique sources from which users downloaded the app: Bing, Google, and others.\n",
    "The majority of users (34,286 events) come from Bing.\n",
    "This suggests that Bing is a significant source of user acquisition for the app.\n",
    "Event Timing:\n",
    "\n",
    "The events span from October 7, 2019, to November 3, 2019.\n",
    "The mean event time is approximately October 21, 2019, indicating a fairly even distribution of events throughout the period.\n",
    "The 25th, 50th, and 75th percentiles of event times further confirm a relatively uniform distribution of user activity over the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of Events Over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(merged_data['event_time'], bins=100, kde=False)\n",
    "plt.title('Distribution of Events Over Time')\n",
    "plt.xlabel('Event Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The chart shows a relatively consistent level of user activity throughout the month. There are regular peaks and troughs, but no prolonged periods of inactivity.\n",
    "This consistency suggests a stable user base that interacts with the application regularly.\n",
    "\n",
    "Weekly Patterns:\n",
    "\n",
    "There appears to be a recurring pattern every few days, with noticeable peaks and dips. This could indicate weekly usage patterns, possibly reflecting user behavior tied to specific days of the week (e.g., weekends vs. weekdays).\n",
    "Activity Peaks:\n",
    "\n",
    "Some of the highest peaks in activity occur around October 8, October 27, October 29, and November 3.\n",
    "These peaks could be associated with specific events or promotions within the app, or they might reflect natural variations in user activity. Investigating the causes of these peaks could provide insights into what drives higher engagement.\n",
    "\n",
    "Mid-Month Increase:\n",
    "\n",
    "There is a noticeable increase in activity starting around October 12 and continuing until around October 24. This mid-month surge could be related to particular marketing efforts, feature releases, or seasonal trends.\n",
    "\n",
    "\n",
    "Let's check the distribution of events within users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Events per User\n",
    "user_activity = merged_data['user_id'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(user_activity, bins=100, kde=False)\n",
    "plt.title('Distribution of Events per User')\n",
    "plt.xlabel('Number of Events')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "High Concentration of Low Activity Users:\n",
    "\n",
    "The majority of users perform a relatively small number of events, with a steep drop-off as the number of events increases.\n",
    "This indicates that most users are not highly active in terms of the number of interactions they have with the app.\n",
    "Long Tail of Highly Active Users:\n",
    "\n",
    "There is a long tail extending to the right, with a small number of users performing a very high number of events.\n",
    "These highly active users, although fewer in number, could be significantly contributing to overall engagement and usage metrics\n",
    "\n",
    "\n",
    "\n",
    "Let's take a look at source distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source distribution for filtered events\n",
    "source_distribution = merged_data['source'].value_counts()\n",
    "\n",
    "# Plot the distribution of sources for filtered events\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=source_distribution.index, y=source_distribution.values)\n",
    "plt.title('Source Distribution for Filtered Events')\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bing being the top source for user acquisition indicates that marketing efforts through Bing are effective. It might be beneficial to analyze why Bing outperforms other sources and whether those strategies can be replicated for Google and other sources.\n",
    "\n",
    "Let's see how user activity throughout the week:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'day_of_week' column\n",
    "merged_data['day_of_week'] = merged_data['event_time'].dt.day_name()\n",
    "\n",
    "# Group by day of the week and count the number of events\n",
    "events_per_day = merged_data['day_of_week'].value_counts().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "\n",
    "# Plot the distribution of events across the days of the week\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=events_per_day.index, y=events_per_day.values)\n",
    "plt.title('Distribution of Events by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday shows the highest number of events, followed closely by Tuesday and Wednesday. This suggests that user engagement is slightly higher at the beginning of the week, potentially due to users being more active after the weekend. Tuesday, Wednesday, and Thursday maintain relatively high and consistent levels of activity. This consistency indicates steady user engagement during the middle of the week. Tuesday, Wednesday, and Thursday maintain relatively high and consistent levels of activity. This consistency indicates steady user engagement during the middle of the week.There is a noticeable increase in activity on Sunday, almost matching the levels seen on weekdays. This rebound suggests that users return to the app as they wind down their weekend and prepare for the upcoming week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each event name\n",
    "event_name_counts = merged_data['event_name'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(event_name_counts)\n",
    "\n",
    "# Plot the distribution of event names\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(x=event_name_counts.index, y=event_name_counts.values)\n",
    "plt.title('Number of Events by Event Name')\n",
    "plt.xlabel('Event Name')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The tips_show event is by far the most common event, with nearly 40,000 ocurrences. This could mean that the feauture showing recommended ads to users is highly used and possibly a key element if user interaction within the app.\n",
    "\n",
    "* The photos_show event (viewing photos in an ad) and the advert_open event (opening an ad post) are the next most frequent events, with photos_show having over 10,000 occurrences and advert_open having around 5,000 occurrences.\n",
    "This suggests that users are actively browsing ads and engaging with the visual content, which is crucial for a marketplace app.\n",
    "\n",
    "* The contacts_show and show_contacts events (clicking to show phone numbers) combined have a significant number of occurrences. This shows that many users are interested in reaching out to sellers, indicating healthy engagement with the ads.\n",
    "\n",
    "* The map event, where users open the map of published ads, also shows notable usage, indicating that location-based browsing is a useful feature for users.\n",
    "\n",
    "* Various search-related events (search_1 to search_7) collectively represent a substantial portion of the interactions. This indicates that users frequently utilize the search functionality to find specific items or ads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to daily active users over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retention_data = merged_data[['user_id', 'event_time']].drop_duplicates()\n",
    "retention_data['event_date'] = retention_data['event_time'].dt.date\n",
    "\n",
    "# Count the number of unique users by date\n",
    "daily_users = retention_data.groupby('event_date')['user_id'].nunique()\n",
    "\n",
    "# Plot the daily active users\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=daily_users)\n",
    "plt.title('Daily Active Users Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Active Users')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart displays the number of unique active users per day over the given time span. \n",
    "\n",
    "General Trend:\n",
    "\n",
    "There is a general upward trend in daily active users from the beginning of the period until around October 22.\n",
    "After October 22, there is more variability, with fluctuations in the number of active users.\n",
    "\n",
    "Initial Increase:\n",
    "\n",
    "The number of active users starts at around 200 and increases steadily until around October 13.\n",
    "This initial increase might be attributed to successful marketing campaigns, user acquisition strategies, or app updates that attracted more users.\n",
    "\n",
    "Mid-Month Spike and Fluctuations:\n",
    "\n",
    "There is a noticeable spike in daily active users around October 21, where the number reaches over 350.\n",
    "Following this peak, the number of active users fluctuates but generally remains above 250 until the end of the month.\n",
    "\n",
    "Late-Month Decline:\n",
    "\n",
    "Towards the end of October, there is a decline in the number of active users, particularly noticeable on October 31 and November 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate session duration for each user\n",
    "merged_data['next_event_time'] = merged_data.groupby('user_id')['event_time'].shift(-1)\n",
    "merged_data['session_duration'] = (merged_data['next_event_time'] - merged_data['event_time']).dt.total_seconds()\n",
    "\n",
    "# Filter to sessions \n",
    "session_threshold = 20 * 60\n",
    "session_data = merged_data[merged_data['session_duration'] < session_threshold]\n",
    "\n",
    "# Plot the distribution of session durations\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(session_data['session_duration'].dropna(), bins=50, kde=True)\n",
    "plt.title('Distribution of Session Durations')\n",
    "plt.xlabel('Session Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of session durations reveals that most sessions are concise, with a significant peak at durations close to 0 seconds, indicating brief interactions likely for quick checks or initial exploration. The distribution is heavily right-skewed, showing that while most sessions are short, some users spend considerably more extended time in the app. The most common session duration is under 50 seconds, suggesting many users quickly check the app or exit shortly after opening it. There is a gradual decline in the frequency of session durations as the duration increases, indicating fewer users stay engaged for extended periods. Although rare, sessions extending to and beyond 1000 seconds (over 16 minutes) suggest that some users are deeply involved, possibly browsing extensively or performing multiple actions within the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We double check data range rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the range of dates in the dataset\n",
    "earliest_date = merged_data['event_time'].min()\n",
    "latest_date = merged_data['event_time'].max()\n",
    "date_range = latest_date - earliest_date\n",
    "total_days = date_range.days\n",
    "\n",
    "# Display the earliest and latest dates, and the total number of days\n",
    "print(f\"Earliest date: {earliest_date}\")\n",
    "print(f\"Latest date: {latest_date}\")\n",
    "print(f\"Total number of days: {total_days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract unique user-event pairs and the first event date for each user\n",
    "user_first_event = merged_data.groupby('user_id')['event_time'].min().reset_index()\n",
    "user_first_event.rename(columns={'event_time': 'first_event_date'}, inplace=True)\n",
    "\n",
    "# Merge the first event date back into the original data\n",
    "merged_data_with_first_event = pd.merge(merged_data, user_first_event, on='user_id')\n",
    "\n",
    "# Calculate the days since the first event for each event\n",
    "merged_data_with_first_event['days_since_first_event'] = (\n",
    "    merged_data_with_first_event['event_time'] - merged_data_with_first_event['first_event_date']\n",
    ").dt.days\n",
    "\n",
    "# Filter data to ensure we are looking at users who have had enough time to be retained\n",
    "filtered_data = merged_data_with_first_event[merged_data_with_first_event['days_since_first_event'] <= 30]\n",
    "\n",
    "# Calculate overall retention rates\n",
    "overall_retention = filtered_data.groupby('days_since_first_event')['user_id'].nunique() / filtered_data['user_id'].nunique()\n",
    "\n",
    "# Plot overall retention rates\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(overall_retention)\n",
    "plt.title(\"27-Day Daily Retention\")\n",
    "plt.xlabel(\"Days Since User First Started\")\n",
    "plt.ylabel(\"Percent Of Users Retained\")\n",
    "plt.ylim(0, 1.05)\n",
    "\n",
    "# Highlight Day 20 retention if it exists within 27 days\n",
    "if 20 in overall_retention.index:\n",
    "    day_20_retention = overall_retention.loc[20]\n",
    "    plt.hlines(y=day_20_retention, xmin=0, xmax=20, linestyles='dotted')\n",
    "    plt.vlines(x=20, ymin=0, ymax=day_20_retention, linestyles='dotted')\n",
    "    plt.text(s=f\"Ex: There were {day_20_retention:.0%} users retained on Day 20\", x=20, y=day_20_retention + .05)\n",
    "\n",
    "# Cohort analysis by start month\n",
    "filtered_data['start_month'] = filtered_data['first_event_date'].values.astype('datetime64[M]')\n",
    "plt.figure(figsize=(12, 6))\n",
    "legend_x = 20\n",
    "legend_y = .55\n",
    "\n",
    "for i, month in enumerate(filtered_data['start_month'].unique()):\n",
    "    dfc = filtered_data[filtered_data['start_month'] == month]\n",
    "    retention_cohort = dfc.groupby('days_since_first_event')['user_id'].nunique() / dfc['user_id'].nunique()\n",
    "    p = plt.plot(retention_cohort)\n",
    "    plt.text(s=pd.to_datetime(month).strftime('%B %Y'), c=p[0].get_color(),\n",
    "             x=legend_x, y=legend_y + (.05 * i), weight='bold')\n",
    "\n",
    "plt.text(s=\"Cohort Month:\", x=legend_x, y=legend_y + (.05 * i) + .05, weight='bold')\n",
    "plt.title(\"27-Day Daily Retention by Cohort Month\")\n",
    "plt.xlabel(\"Days Since User First Started\")\n",
    "plt.ylabel(\"Percent Of Users Retained\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall 27-Day Retention Rate\n",
    "\n",
    "The first chart shows the overall 27-day retention rate for users. Key observations include:\n",
    "Initial Drop: Retention sharply declines within the first day, dropping from 100% to below 20%. This suggests that a significant number of users do not return after their initial interaction with the app.\n",
    "Gradual Decline: After the initial drop, the retention rate declines gradually over the next few days, stabilizing around 5% by day ten and remaining low for the rest of the 27 days.\n",
    "Low Long-Term Retention: By day 20, retention rates are meager, around 1%. This indicates that only a tiny fraction of users remain active after three weeks.\n",
    "Overall, the retention rate suggests challenges in keeping users engaged beyond their first few interactions with the app.\n",
    "\n",
    "\n",
    "27-Day Retention by Cohort Month\n",
    "The second chart breaks down the 27-day retention by cohort month (October 2019 and November 2019). Key insights include:\n",
    "Consistent Initial Drop: Both cohorts exhibit a similar sharp decline in retention within the first day, dropping from 100% to below 20%. This reinforces the observation that many users do not return after their initial use.\n",
    "Similar Retention Patterns: The retention patterns for both cohorts follow a similar trend, with a gradual decline in the subsequent days. However, the October cohort has slightly better retention in the early days than the November cohort.\n",
    "Cohort Comparison: The slight variation between the cohorts suggests that factors specific to each month (e.g., marketing campaigns app updates) may influence retention rates, but the overall trend remains consistent.\n",
    "The cohort analysis highlights that retention challenges are consistent across different months, and efforts to improve user engagement should focus on addressing the significant drop-off after the first day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define Metrics for Segmentation\n",
    "\n",
    "    We will define several metrics that can help us understand user behavior:\n",
    "\n",
    "* Customer Age: Time from the first event to the last event.\n",
    "* Activity Level: Total number of events.\n",
    "* Engagement with Key Features: Frequency of specific events like contacts_show, photos_show.\n",
    "* Recency: Time since the last event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_event_times = merged_data.groupby('user_id')['event_time'].agg(['min', 'max']).reset_index()\n",
    "user_event_times.rename(columns={'min': 'first_event_time', 'max': 'last_event_time'}, inplace=True)\n",
    "\n",
    "# Calculate customer age (time between first and last event)\n",
    "user_event_times['customer_age_days'] = (user_event_times['last_event_time'] - user_event_times['first_event_time']).dt.days\n",
    "\n",
    "# Calculate total number of events per user\n",
    "user_event_counts = merged_data.groupby('user_id')['event_time'].count().reset_index()\n",
    "user_event_counts.rename(columns={'event_time': 'total_events'}, inplace=True)\n",
    "\n",
    "# Calculate frequency of specific events\n",
    "event_freq = merged_data.pivot_table(index='user_id', columns='event_name', aggfunc='size', fill_value=0).reset_index()\n",
    "\n",
    "# Calculate recency (time since the last event)\n",
    "current_time = merged_data['event_time'].max()\n",
    "user_event_times['recency_days'] = (current_time - user_event_times['last_event_time']).dt.days\n",
    "\n",
    "# Merge all metrics into a single DataFrame\n",
    "user_metrics = user_event_times.merge(user_event_counts, on='user_id').merge(event_freq, on='user_id')\n",
    "\n",
    "\n",
    "features = user_metrics[['customer_age_days', 'total_events', 'recency_days']]\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Apply k-means with 4 clusters \n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "user_metrics['cluster'] = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "# Calculate the average metrics for each cluster\n",
    "cluster_summary = user_metrics.groupby('cluster').agg({\n",
    "    'user_id': 'count',\n",
    "    'customer_age_days': 'mean',\n",
    "    'total_events': 'mean',\n",
    "    'recency_days': 'mean'\n",
    "}).reset_index()\n",
    "cluster_summary.rename(columns={'user_id': 'count'}, inplace=True)\n",
    "\n",
    "# Display the cluster summaries\n",
    "display(cluster_summary)\n",
    "\n",
    "# Visualize the clusters\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='cluster', y='count', data=cluster_summary)\n",
    "plt.title('Number of Users in Each Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()\n",
    "\n",
    "# Additional visualizations for key metrics within each cluster\n",
    "metrics = ['customer_age_days', 'total_events', 'recency_days']\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='cluster', y=metric, data=cluster_summary)\n",
    "    plt.title(f'Average {metric.replace(\"_\", \" \").title()} in Each Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel(f'Average {metric.replace(\"_\", \" \").title()}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user segmentation has been performed using k-means clustering, and the users have been segmented into four distinct groups. \n",
    "\n",
    "**Insights**\n",
    "\n",
    "**Number of Users in Each Cluster**\n",
    "\n",
    "* Cluster 0: This cluster has the highest number of users.\n",
    "* Cluster 3: This cluster has the fewest users.\n",
    "* Cluster 1 and Cluster 2: These clusters have a moderate number of users, with Cluster 1 having slightly more than Cluster 2.\n",
    "\n",
    "**Average Customer Age in Each Cluster**\n",
    "\n",
    "* Cluster 0: Users in this cluster have the shortest average customer age, indicating they are relatively new users.\n",
    "* Cluster 3: Users in this cluster have the longest average customer age, indicating they are the most loyal and long-term users.\n",
    "* Cluster 1 and Cluster 2: These clusters have users with moderate customer age, indicating they have been active for a while but not as long as Cluster 3.\n",
    "\n",
    "**Average Total Events in Each Cluster**\n",
    "\n",
    "* Cluster 0: Users in this cluster have the lowest average total events, indicating low engagement.\n",
    "* Cluster 3: Users in this cluster have the highest average total events, indicating very high engagement.\n",
    "* Cluster 1 and Cluster 2: Users in these clusters have moderate engagement, with Cluster 2 slightly more engaged than Cluster 1.\n",
    "\n",
    "**Average Recency in Each Cluster**\n",
    "\n",
    "* Cluster 0: Users in this cluster have the highest average recency, indicating that it has been a long time since their last activity. They are likely at risk of churn.\n",
    "* Cluster 3: Users in this cluster have the lowest average recency, indicating they have interacted with the app recently and are actively engaged.\n",
    "* Cluster 1 and Cluster 2: Users in these clusters have moderate recency, indicating they are somewhat engaged but not as recent as Cluster 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Statistical Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis 1: Difference in Conversion in Contact Information Views between bing and google**\n",
    "\n",
    "Conversion in Contact Information Views:\n",
    "\n",
    "* We define conversion as the event where a user views contact information (contacts_show).\n",
    "\n",
    "Formulate Hypotheses:\n",
    "\n",
    "**Null Hypothesis (H0):**  There is no difference in the conversion rate of contact information views between users who downloaded the app from bing and those who downloaded it from google.\n",
    "\n",
    "**Alternative Hypothesis (H1):** There is a difference in the conversion rate of contact information views between users who downloaded the app from bing and those who downloaded it from google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will:\n",
    "\n",
    "1. Calculate the conversion rate for each group (bing and google).\n",
    "2. Since we are comparing the conversion rates between two groups (users who downloaded the app from bing vs. google), it is appropriate to use a chi-square test for independence. This is because we are dealing with categorical data and we want to see if there is a significant difference in the distribution of conversion events (contacts_show) between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filter the data for users from bing and google\n",
    "bing_users = merged_data[merged_data['source'] == 'bing']\n",
    "google_users = merged_data[merged_data['source'] == 'google']\n",
    "\n",
    "# Calculate the number of unique users who performed the 'contacts_show' event for each group\n",
    "bing_conversion_users = bing_users[bing_users['event_name'] == 'contacts_show']['user_id'].nunique()\n",
    "google_conversion_users = google_users[google_users['event_name'] == 'contacts_show']['user_id'].nunique()\n",
    "\n",
    "# Calculate the total number of unique users for each group\n",
    "bing_total_users = bing_users['user_id'].nunique()\n",
    "google_total_users = google_users['user_id'].nunique()\n",
    "\n",
    "# Calculate the number of users who did not convert (did not perform 'contacts_show')\n",
    "bing_no_conversion_users = bing_total_users - bing_conversion_users\n",
    "google_no_conversion_users = google_total_users - google_conversion_users\n",
    "\n",
    "# Debugging output :(\n",
    "print(f\"Bing: Total Users = {bing_total_users}, Conversions = {bing_conversion_users}, No Conversions = {bing_no_conversion_users}\")\n",
    "print(f\"Google: Total Users = {google_total_users}, Conversions = {google_conversion_users}, No Conversions = {google_no_conversion_users}\")\n",
    "\n",
    "# Create a contingency table\n",
    "conversion_table = pd.DataFrame({\n",
    "    'Conversion': [bing_conversion_users, google_conversion_users],\n",
    "    'No Conversion': [bing_no_conversion_users, google_no_conversion_users]\n",
    "}, index=['Bing', 'Google'])\n",
    "\n",
    "print(\"\\nContingency Table:\")\n",
    "print(conversion_table)\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, ex = stats.chi2_contingency(conversion_table)\n",
    "print(f\"\\nChi-square Test:\\nChi2: {chi2}\\np-value: {p}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference in conversion rates between Bing and Google users.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in conversion rates between Bing and Google users.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion rates from those who donwloaded the app from Bing and Google are very similar, both around 24-25%\n",
    "\n",
    "Chi-Square Test:\n",
    "\n",
    "The chi-square statistic is very low (0.0318), indicating little difference between the observed conversion rates and what we would expect if there were no real difference.\n",
    "The p-value (0.8584) is much higher than the typical significance level (0.05), meaning we fail to reject the null hypothesis.\n",
    "Conclusion\n",
    "\n",
    "Fail to Reject the Null Hypothesis:\n",
    "\n",
    "Based on the chi-square test, we do not have enough evidence to conclude that there is a significant difference in the conversion rates between users who downloaded the app from Bing and those who downloaded it from Google.\n",
    "This suggests that the source of the download (Bing vs. Google) does not significantly affect whether users view contact information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2: General Dataset Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's formulate a simple hypothesis about the general dataset. For example, we can test whether the average number of events per user is significantly different from a hypothetical value (e.g., 20).\n",
    "\n",
    "Formulate Hypothesis:\n",
    "\n",
    "**Null Hypothesis (H0):** The average number of events per user is equal to 20.\n",
    "\n",
    "**Alternative Hypothesis (H1):** The average number of events per user is not equal to 20.\n",
    "\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Calculate the average number of events per user.\n",
    "2. Perform a one-sample t-test to compare the sample mean to the hypothetical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average number of events per user\n",
    "avg_events_per_user = merged_data.groupby('user_id').size().mean()\n",
    "print(f\"Average Number of Events per User: {avg_events_per_user:.2f}\")\n",
    "\n",
    "# Perform one-sample t-test\n",
    "hypothetical_mean = 20\n",
    "events_per_user = merged_data.groupby('user_id').size()\n",
    "t_stat, p_value = ttest_1samp(events_per_user, hypothetical_mean)\n",
    "print(f\"\\nOne-Sample t-Test:\\nt-statistic: {t_stat}\\np-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The average number of events per user is significantly different from 20.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The average number of events per user is not significantly different from 20.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "\n",
    "The primary objective of this project was to analyze user behavior within the \"Trash to Treasure\" mobile app and to segment users based on their interactions. This segmentation aims to enhance user engagement and retention through targeted strategies\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "**Data Loading and Preparation:**\n",
    "\n",
    "* Successfully loaded and merged datasets.\n",
    "* Standardized column names and handled event name inconsistencies.\n",
    "\n",
    "**Exploratory Data Analysis (EDA):**\n",
    "\n",
    "* Performed comprehensive EDA to understand event distribution, user activity, and source effectiveness.\n",
    "* Identified key insights such as the dominance of the tips_show event and the significant user base acquired from Bing.\n",
    "\n",
    "**User Segmentation:**\n",
    "\n",
    "* Defined segmentation criteria based on customer age, total events, and recency.\n",
    "* Applied k-means clustering to segment users into four distinct clusters.\n",
    "* Analyzed the characteristics of each cluster to understand user behavior patterns.\n",
    "\n",
    "**Hypothesis Testing:**\n",
    "\n",
    "* Tested the hypothesis regarding the difference in conversion rates between users from Bing and Google.\n",
    "* Conducted a one-sample t-test to compare the average number of events per user against a hypothetical value.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "**Improve User Onboarding:** Enhance the onboarding experience to better engage new users and reduce the initial drop-off rate.\n",
    "\n",
    "**Engagement Strategies:** Develop strategies to increase user engagement, especially for users in Segment 0, to move them towards higher activity levels.\n",
    "\n",
    "**Retention Programs:** Implement retention programs targeting users who have been active for a few days but are at risk of churn.\n",
    "\n",
    "**Analyze High-Engagement Users:** Study the behavior of high-engagement users (Segment 1) to identify features or patterns that can be promoted to other users.\n",
    "\n",
    "### Limitations and Implications\n",
    "\n",
    "* Data Limitations: The analysis is limited to the available data, which may not capture all aspects of user behavior.\n",
    "\n",
    "* Model Improvements: Future research could explore more advanced segmentation techniques and machine learning models to better understand user behavior.\n",
    "\n",
    "\n",
    "**Ethical and Privacy Implications**\n",
    "\n",
    "When working with user behavioral data, it is essential to address ethical and privacy considerations:\n",
    "\n",
    "    * Data Anonymization: Ensure that user data is anonymized to protect user identities.\n",
    "    * Informed Consent: Users should be informed about the data collection practices and consent to their data being used.\n",
    "    * Data Security: Implement strong security measures to protect user data from unauthorized access.\n",
    "    * Transparency: Be transparent about how user data is being used and provide users with the option to opt out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
